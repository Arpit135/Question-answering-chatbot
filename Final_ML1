{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8215006,"sourceType":"datasetVersion","datasetId":4869074}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch sentence-transformers\n!pip install PyPDF2\n!pip install sentence-transformers\n#!pip install openai==0.28\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nimport spacy\nimport torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n#import openai\n#from transformers import LlamaTokenizer, LlamaForCausalLM\nfrom sentence_transformers import SentenceTransformer, util\n\nimport PyPDF2\nimport re\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T06:35:49.282681Z","iopub.execute_input":"2024-04-26T06:35:49.283341Z","iopub.status.idle":"2024-04-26T06:36:39.506215Z","shell.execute_reply.started":"2024-04-26T06:35:49.283308Z","shell.execute_reply":"2024-04-26T06:36:39.505169Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nCollecting sentence-transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.7.0\nCollecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.7.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n/kaggle/input/bladerunner/blade runner 2049.pdf\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(\"/kaggle/input/bladerunner/blade runner 2049.pdf\", \"rb\") as pdf_file:\n    # Create a PDF reader object\n    pdf_reader = PyPDF2.PdfReader(pdf_file)\n\n    # Initialize an empty string to store the extracted text\n    text = ''\n\n    # Loop through each page and extract the text\n    for page in pdf_reader.pages:\n        text += page.extract_text()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:36:49.547147Z","iopub.execute_input":"2024-04-26T06:36:49.548174Z","iopub.status.idle":"2024-04-26T06:36:50.838723Z","shell.execute_reply.started":"2024-04-26T06:36:49.548140Z","shell.execute_reply":"2024-04-26T06:36:50.837726Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"num_parts = 1250\npart_size = len(text) // num_parts\ntext_parts = []\nfor i in range(num_parts):\n    start_index = i * part_size\n    end_index = (i + 1) * part_size if i < num_parts - 1 else len(text)\n    text_part = text[start_index:end_index]\n    text_parts.append(text_part)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:36:53.437833Z","iopub.execute_input":"2024-04-26T06:36:53.438901Z","iopub.status.idle":"2024-04-26T06:36:53.447523Z","shell.execute_reply.started":"2024-04-26T06:36:53.438842Z","shell.execute_reply":"2024-04-26T06:36:53.446412Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#import spacy\ndef evaluate(text_parts,my_query):  \n#     nlp = spacy.load(\"en_core_web_md\")\n#     # Define the query and convert it to a spaCy Doc object\n#     query = my_query\n#     query_doc = nlp(query)\n\n#     # Calculate semantic similarity scores between the query and each sentence\n#     scores = []\n#     for text_part in text_parts:\n#         sentence_doc = nlp(text_part)\n#         similarity_score = query_doc.similarity(sentence_doc)\n#         scores.append((text_part, similarity_score))\n\n#     # Sort sentences by similarity score (optional)\n#     scores.sort(key=lambda x: x[1], reverse=True)\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n#     # Define the query\n    query = my_query\n\n    # Compute embedding for the query and the sentences\n    query_embedding = model.encode([query], convert_to_tensor=True)\n    sentence_embeddings = model.encode(text_parts, convert_to_tensor=True)\n\n    # Compute cosine-similarities\n    cosine_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)\n\n\n    # Create a list of tuples containing sentence and cosine similarity score\n    scores = [(text_parts[i], cosine_scores[0][i].item()) for i in range(len(text_parts))]\n\n    # Sort scores in decreasing order\n    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n\n    # Create a dictionary to store total weighted score for each sentence\n    score_dict = {}\n    weight = 1\n    #for pairs, weight in zip([normalized_scores], [0.2, 0.6, 0.2]):\n    for text_part, score in scores:\n        if text_part not in score_dict:\n            score_dict[text_part] = 0\n        score_dict[text_part] += weight * score\n\n    # Now score_dict contains the weighted average score for each sentence\n    weighted_scores = list(score_dict.items())\n\n    # Sort scores in decreasing order\n    weighted_scores.sort(key=lambda x: x[1], reverse=True)\n\n\n    return weighted_scores","metadata":{"execution":{"iopub.status.busy":"2024-04-26T07:34:14.040984Z","iopub.execute_input":"2024-04-26T07:34:14.041369Z","iopub.status.idle":"2024-04-26T07:34:14.051527Z","shell.execute_reply.started":"2024-04-26T07:34:14.041337Z","shell.execute_reply":"2024-04-26T07:34:14.050790Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model_name = \"google/flan-t5-large\"  # You can choose larger models like flan-t5-large\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\nquestion = \"Who is the writer?\"\n#question =  \"Explain the theme of the movie\"\n#question =  \"Who are the characters?\"\n#question =  \"Does the script pass the Bechdel test?\"\nweighted_scores = evaluate(text_parts, question)\n\n# Construct the context by combining the top-weighted scores\ncontext = \". \".join([score[0] for score in weighted_scores[:min(10,len(weighted_scores))]]) + \".\"\n\n# Create a prompt with the context and the question\nprompt = f\"{context}\\nQuestion: {question}\\nAnswer:\"\n\ninput_ids = tokenizer.encode(prompt, return_tensors='pt')\n#output = model.generate(input_ids, max_length=50)\n\noutput = model.generate(\n    input_ids,\n    max_length=500,  # Increase max_length for longer responses\n    temperature=1.1,  # Adjust temperature for more varied output\n    top_k=50,  # Control sampling diversity\n    top_p=0.95,  # Control the probability distribution for output tokens\n    num_return_sequences=1,  # Return multiple sequences if you want to select the best one\n    do_sample=True  # Enable sampling for varied outputs\n)\n\n# Decode the output to get the generated answer\nanswer = tokenizer.decode(output[0], skip_special_tokens=True)\n#print(context)\nprint(\"Answer:\", answer)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T08:14:10.709035Z","iopub.execute_input":"2024-04-26T08:14:10.709746Z","iopub.status.idle":"2024-04-26T08:14:16.685905Z","shell.execute_reply.started":"2024-04-26T08:14:10.709704Z","shell.execute_reply":"2024-04-26T08:14:16.684932Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d0d00bbb8e43f0a97116a5656a071d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5796b53aa2c4ef9ad6821f49d229a75"}},"metadata":{}},{"name":"stdout","text":"Answer: yes\n","output_type":"stream"}]}]}